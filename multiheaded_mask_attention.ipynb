{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ab7852-0cc5-48ee-9050-d3a64fe609a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1442, -0.1154,  0.2019],\n",
      "         [-0.1439, -0.1152,  0.2020]]], grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the input tensor\n",
    "#x = torch.randn(1, 2, 3)\n",
    "x = torch.tensor([[[-0.17, -0.29, -0.61],\n",
    "                   [ 0.48, -1.10, -0.38]]])\n",
    "\n",
    "c = torch.tensor([[[-0.67, -0.2996, -0.6140],\n",
    "                   [ 0.52, 0.95, -0.58]]])\n",
    "\n",
    "# Create the multi-head attention layer\n",
    "layer = nn.MultiheadAttention(embed_dim=3, num_heads=1, bias=False, batch_first=True)\n",
    "\n",
    "custom_weights = torch.tensor( [[-0.3561,  0.3674, -0.5108],\n",
    "                                [ 0.5146, -0.4764, -0.1490],\n",
    "                                [ 0.5072, -0.2932, -0.5633],\n",
    "                                [-0.4932, -0.4468,  0.0736],\n",
    "                                [-0.6879, -0.4689, -0.1026],\n",
    "                                [ 0.1847,  0.1858,  0.4469],\n",
    "                                [-0.4110, -0.4083, -0.5549],\n",
    "                                [ 0.3921, -0.0746, -0.1336],\n",
    "                                [-0.6555, -0.3418, -0.2980]]).float()\n",
    "layer.in_proj_weight = nn.Parameter(custom_weights)\n",
    "\n",
    "custom_out_proj = torch.tensor([[-0.3601,  0.2771, -0.0573],\n",
    "                                [-0.0896,  0.0567, -0.2882],\n",
    "                                [ 0.3200,  0.1517,  0.0580]]).float()\n",
    "layer.out_proj.weight = nn.Parameter(custom_out_proj)\n",
    "\n",
    "# Perform the forward pass\n",
    "# You can use x for both queries, keys, and values in this example\n",
    "output_tensor, attn_output_weights = layer(c, x, x)  \n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a83dc6-0238-49a5-a90a-88dcee2af372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f76bde34-4de3-4b05-b6c4-a46716fc5f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0305, -0.0296,  0.0677],\n",
      "         [-0.0281, -0.0277,  0.0630]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the input tensor\n",
    "x = torch.tensor([[[-0.1, 0.1,  0.3],\n",
    "                   [ 0.4, -1.1, -0.3]]])\n",
    "\n",
    "c = torch.tensor([[[-0.6, 0.3, -0.4],\n",
    "                   [ 0.5, 0.9, -0.5]]])\n",
    "\n",
    "q = torch.tensor(  [[-0.3561,  0.3674, -0.5108],\n",
    "                    [ 0.5146, -0.4764, -0.1490],\n",
    "                    [ 0.5072, -0.2932, -0.5633]]).float()\n",
    "k = torch.tensor(  [[-0.4932, -0.4468,  0.0736],\n",
    "                    [-0.6879, -0.4689, -0.1026],\n",
    "                    [ 0.1847,  0.1858,  0.4469]]).float()\n",
    "v = torch.tensor(  [[-0.4110, -0.4083, -0.5549],\n",
    "                    [ 0.3921, -0.0746, -0.1336],\n",
    "                    [-0.6555, -0.3418, -0.2980]]).float()\n",
    "o = torch.tensor([[-0.3601,  0.2771, -0.0573],\n",
    "                  [-0.0896,  0.0567, -0.2882],\n",
    "                  [ 0.3200,  0.1517,  0.0580]]).float()\n",
    "\n",
    "# Define the model parameters\n",
    "embed_dim = 3\n",
    "num_heads = 1\n",
    "head_dim = embed_dim // num_heads\n",
    "\n",
    "# Step 1: Linear projections for queries, keys, and values\n",
    "query_proj = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "key_proj = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "value_proj = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "\n",
    "# Custom weights for linear projections\n",
    "query_proj.weight = nn.Parameter(q)\n",
    "key_proj.weight = nn.Parameter(k)\n",
    "value_proj.weight = nn.Parameter(v)\n",
    "\n",
    "# Step 2: Split the input into multiple heads\n",
    "query = query_proj(c)\n",
    "key = key_proj(x)\n",
    "value = value_proj(x)\n",
    "\n",
    "# Reshape query, key, and value to have shape (batch_size, num_heads, seq_len, head_dim)\n",
    "query = query.view(1, num_heads, -1, head_dim)\n",
    "key = key.view(1, num_heads, -1, head_dim)\n",
    "value = value.view(1, num_heads, -1, head_dim)\n",
    "\n",
    "# Step 3: Compute scaled dot-product attention\n",
    "attention_scores = torch.matmul(query, key.transpose(-2, -1)) / (head_dim ** 0.5)\n",
    "attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "context = torch.matmul(attention_weights, value)\n",
    "\n",
    "# Step 4: Concatenate and project back\n",
    "context = context.view(1, -1, embed_dim)\n",
    "out_proj = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "out_proj.weight = nn.Parameter(o)\n",
    "output = out_proj(context)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede07953-b37e-47ee-a04e-b0b00cbadd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "[],\n",
    "         []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4940c7f0-3798-496c-a808-077e532a6b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0305, -0.0296,  0.0677],\n",
      "        [-0.0281, -0.0277,  0.0630]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the input tensor\n",
    "x = torch.tensor([[[-0.1, 0.1,  0.3],\n",
    "                   [ 0.4, -1.1, -0.3]]])\n",
    "\n",
    "c = torch.tensor([[[-0.6, 0.3, -0.4],\n",
    "                   [ 0.5, 0.9, -0.5]]])\n",
    "\n",
    "q = torch.tensor(  [[-0.3561,  0.3674, -0.5108],\n",
    "                    [ 0.5146, -0.4764, -0.1490],\n",
    "                    [ 0.5072, -0.2932, -0.5633]]).float()\n",
    "k = torch.tensor(  [[-0.4932, -0.4468,  0.0736],\n",
    "                    [-0.6879, -0.4689, -0.1026],\n",
    "                    [ 0.1847,  0.1858,  0.4469]]).float()\n",
    "v = torch.tensor(  [[-0.4110, -0.4083, -0.5549],\n",
    "                    [ 0.3921, -0.0746, -0.1336],\n",
    "                    [-0.6555, -0.3418, -0.2980]]).float()\n",
    "o = torch.tensor([[-0.3601,  0.2771, -0.0573],\n",
    "                  [-0.0896,  0.0567, -0.2882],\n",
    "                  [ 0.3200,  0.1517,  0.0580]]).float()\n",
    "\n",
    "# Define the model parameters\n",
    "embed_dim = 3\n",
    "num_heads = 1\n",
    "head_dim = embed_dim // num_heads\n",
    "\n",
    "# Step 1: Linear projections for queries, keys, and values\n",
    "query = c@q.T\n",
    "key = x@k.T\n",
    "value = x@v.T\n",
    "\n",
    "# Reshape query, key, and value to have shape (batch_size, num_heads, seq_len, head_dim)\n",
    "query = query.view(num_heads, -1, head_dim)\n",
    "key = key.view(num_heads, -1, head_dim)\n",
    "value = value.view(num_heads, -1, head_dim)\n",
    "\n",
    "# Step 3: Compute scaled dot-product attention\n",
    "attention_scores = torch.matmul(query, key.transpose(-2, -1)) / (head_dim ** 0.5)\n",
    "attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "context = torch.matmul(attention_weights, value)\n",
    "\n",
    "# Step 4: Concatenate and project back\n",
    "context = context.view(-1, embed_dim)\n",
    "output = context@o.T\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c75211-2a09-4597-8bef-7dc671e4962f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
